{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 16 key-value pairs and 291 tensors from /Users/alanngo/Desktop/projects/models/llama2/ggml-model-q5_k_m.gguf.bin (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = llama2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 4.45 GiB (5.68 BPW) \n",
      "llm_load_print_meta: general.name     = llama2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4474.94 MiB, ( 9281.61 / 21845.34)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4474.93 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/alanngo/Desktop/projects/models/langchainenv/lib/python3.9/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 22906.50 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   256.00 MiB, ( 9537.61 / 21845.34)\n",
      "llama_kv_cache_init:      Metal KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 9537.62 / 21845.34)\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    73.02 MiB, ( 9610.62 / 21845.34)\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "llama_new_context_with_model:      Metal compute buffer size =    73.00 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     9.00 MiB\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '2048', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '17', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'llama2'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "For red wine suggestion, provide the following information:\n",
    "Suggest a wine that pair well with the food.\n",
    "\n",
    "[INST] {input} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"/Users/alanngo/Desktop/projects/models/llama2/ggml-model-q5_k_m.gguf.bin\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True  # Verbose is required to pass to the callback manager\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [\"What wine best with fish\",\n",
    "                 \"What wine best with steak\",\n",
    "                 \"what wine best with human\",\n",
    "                 \"I am having a chinese food tonight\",\n",
    "                 \"I am having a japanese food tonight and I have limited budget\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_free: deallocating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When it comes to pairing wine with fish, you'll want to choose a wine that complements the flavors and textures of the dish without overpowering them. Here are some red wine suggestions that pair well with fish:\n",
      "1. Pinot Noir - A light-bodied red wine with red fruit flavors and high acidity, Pinot Noir pairs well with lighter fish dishes such as grilled salmon or seared scallops.\n",
      "2. Beaujolais - This wine is known for its bright acidity and fruity flavors, making it a great match for delicate fish like sole or flounder.\n",
      "3. Grenache - A medium-bodied red wine with soft tannins and flavors of red fruit, Grenache pairs well with richer fish dishes such as pan-seared tuna or grilled swordfish.\n",
      "4. Syrah/Shiraz - This full-bodied red wine has a robust flavor profile with notes of dark fruit, spice, and pepper, making it a great match for heartier fish dishes like grilled halibut or sea bass.\n",
      "5. Tempranillo -/n\n",
      "For ste"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     451.88 ms\n",
      "llama_print_timings:      sample time =      42.11 ms /   256 runs   (    0.16 ms per token,  6079.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     451.82 ms /    41 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8951.84 ms /   255 runs   (   35.11 ms per token,    28.49 tokens per second)\n",
      "llama_print_timings:       total time =   10262.18 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ak, a full-bodied red wine with a high tannin level is ideal to complement its rich flavor and juiciness. Here are some classic red wine pairs for steak:\n",
      "1. Cabernet Sauvignon - A classic pairing that works well with grilled or pan-seared steaks, especially those cooked to medium-rare or medium doneness. The tannins in Cabernet Sauvignon help balance the fattiness of the meat and complement its bold flavors.\n",
      "2. Syrah/Shiraz - A robust and spicy red wine that pairs well with grilled or roasted steaks, especially those seasoned with herbs like rosemary or thyme. The dark fruit flavors in Syrah/Shiraz complement the richness of the meat without overpowering it.\n",
      "3. Malbec - A smooth and fruity red wine that pairs well with grilled or pan-seared steaks, especially those seasoned with chimmichurri or other herbs. The moderate tannins in Malbec help balance the richness of the meat without overpowering it.\n",
      "4. Merlot - A mellow and/n\n",
      "Hum"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     451.88 ms\n",
      "llama_print_timings:      sample time =      48.62 ms /   256 runs   (    0.19 ms per token,  5265.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     143.37 ms /     7 tokens (   20.48 ms per token,    48.83 tokens per second)\n",
      "llama_print_timings:        eval time =    9018.51 ms /   255 runs   (   35.37 ms per token,    28.28 tokens per second)\n",
      "llama_print_timings:       total time =   10139.24 ms /   262 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans are complex and diverse, so it's difficult to recommend just one wine that pairs well with all of them! However, I can suggest some general guidelines for choosing a red wine that might complement various human flavors:\n",
      "\n",
      "1. Earthy or mushroom-forward dishes: A rich, full-bodied red wine with high tannins and acidity can help balance the richness of earthy or mushroom-based dishes. Some good options include Cabernet Sauvignon, Syrah/Shiraz, or Malbec.\n",
      "2. Hearty stews or braises: A bold, full-bodied red wine with high tannins and acidity can help stand up to the richness of hearty stews or braises. Some good options include Cabernet Sauvignon, Pinot Noir, or Syrah/Shiraz.\n",
      "3. Spicy dishes: A medium-bodied red wine with moderate tannins and acidity can help balance the heat of spicy dishes. Some good options include Grenache, Tempranillo, or Sangiovese.\n",
      "4. Rich desserts: A sweet/n\n",
      "Ah,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     451.88 ms\n",
      "llama_print_timings:      sample time =      43.41 ms /   256 runs   (    0.17 ms per token,  5896.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     144.69 ms /    10 tokens (   14.47 ms per token,    69.11 tokens per second)\n",
      "llama_print_timings:        eval time =    8990.13 ms /   255 runs   (   35.26 ms per token,    28.36 tokens per second)\n",
      "llama_print_timings:       total time =   10026.84 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " perfect! Chinese cuisine offers a wide range of flavors and textures, so you'll want a wine that can complement those flavors without overpowering them. Here are some red wine suggestions that pair well with Chinese food:\n",
      "1. Pinot Noir - This light-bodied red wine is a great choice for lighter Chinese dishes like stir-fries or noodle dishes. It has bright acidity and red fruit flavors that will complement the delicate flavors of these dishes without overpowering them.\n",
      "2. Beaujolais - This red wine from France is known for its fruity and light-bodied character, making it a great match for Chinese food with bold flavors like kung pao chicken or mapo tofu. The wine's fruitiness will complement the rich and savory flavors of these dishes without overpowering them.\n",
      "3. Merlot - This smooth and approachable red wine is a good choice for heartier Chinese dishes like Peking duck or beef with broccoli. Its plum and blackberry flavors will complement the rich and savory flavors of these dishes nicely, without/n\n",
      "Ah,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     451.88 ms\n",
      "llama_print_timings:      sample time =      42.89 ms /   256 runs   (    0.17 ms per token,  5968.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     144.79 ms /    14 tokens (   10.34 ms per token,    96.69 tokens per second)\n",
      "llama_print_timings:        eval time =    9013.30 ms /   255 runs   (   35.35 ms per token,    28.29 tokens per second)\n",
      "llama_print_timings:       total time =   10024.37 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " excellent! In that case, here are some affordable red wine suggestions that pair well with Japanese cuisine:\n",
      "\n",
      "1. Kekō Magnum 2017 - This is a great value red wine from Chile that has a medium body and flavors of plum, cherry, and hints of spice. It pairs nicely with grilled meats, sushi, and tempura. ( around $15)\n",
      "2. Bodega Garzón Chardonnay 2018 - From Uruguay, this chardonnay has a medium body with flavors of green apple, pear, and a hint of oak. It's a great pairing for sushi rolls, tempura, and grilled meats. (around $15)\n",
      "3. Marques de Riscal Rioja 2016 - A classic Spanish red wine with a medium body and flavors of dark fruit, spice, and a hint of vanilla. It pairs well with grilled meats, roasted vegetables, and noodle dishes. (around $20)\n",
      "4. Santa Margherita Pinot Grigio 2019/n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     451.88 ms\n",
      "llama_print_timings:      sample time =      39.41 ms /   256 runs   (    0.15 ms per token,  6496.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     144.49 ms /    16 tokens (    9.03 ms per token,   110.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8998.49 ms /   255 runs   (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_print_timings:       total time =    9941.31 ms /   271 tokens\n"
     ]
    }
   ],
   "source": [
    "for question in question_list:\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=False)\n",
    "    llm_chain.run(question)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_chain.run(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
